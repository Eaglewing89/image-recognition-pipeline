{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5496009",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83848c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2963bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "GPU: NVIDIA GeForce RTX 3070 with 8.00 GB memory\n",
      "CUDNN benchmark enabled for performance optimization\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check for GPU availability and set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Print GPU info if available\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # Convert to GB\n",
    "    print(f\"GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n",
    "    \n",
    "    # Additional GPU optimization for RTX 3070 (8GB VRAM)\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize for fixed input sizes\n",
    "    print(\"CUDNN benchmark enabled for performance optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e02fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 training files and 3 test files\n",
      "\n",
      "Training data summary:\n",
      "Number of classes: 10\n",
      "Class names: ['spider', 'dog', 'chicken', 'horse', 'butterfly', 'squirrel', 'cow', 'sheep', 'cat', 'elephant']\n",
      "Class weights tensor shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import mlflow\n",
    "import glob\n",
    "import os\n",
    "from functions.utility import analyze_webdataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"webdataset\")\n",
    "\n",
    "# Configure MLflow\n",
    "mlflow.set_experiment(\"animals10\")\n",
    "\n",
    "# Define constants\n",
    "DATA_DIR = \"./data/webdataset/\"\n",
    "\n",
    "# Relative file paths\n",
    "config.TRAIN_PATHS = sorted(glob.glob(os.path.join(DATA_DIR, \"train-*.tar\")))\n",
    "config.TEST_PATHS = sorted(glob.glob(os.path.join(DATA_DIR, \"test-*.tar\")))\n",
    "# Absolute paths\n",
    "# config.TRAIN_PATHS = sorted([os.path.abspath(path) for path in glob.glob(os.path.join(DATA_DIR, \"train-*.tar\"))])\n",
    "# config.TEST_PATHS = sorted([os.path.abspath(path) for path in glob.glob(os.path.join(DATA_DIR, \"test-*.tar\"))])\n",
    "\n",
    "\n",
    "print(f\"Found {len(config.TRAIN_PATHS)} training files and {len(config.TEST_PATHS)} test files\")\n",
    "\n",
    "num_classes, class_names, class_weights = analyze_webdataset(DATA_DIR, verbose=False)\n",
    "print(f\"\\nTraining data summary:\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Class weights tensor shape: {class_weights.shape}\")\n",
    "\n",
    "# Update the config module variables\n",
    "config.NUM_CLASSES = num_classes\n",
    "config.CLASS_NAMES = class_names\n",
    "config.CLASS_WEIGHTS = class_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8636f",
   "metadata": {},
   "source": [
    "### Hyperparameter search\n",
    "3 fold cross validation was used. \n",
    "\n",
    "Aggressive pruning by first fold minimum threshold as well as optunas median pruning strategy by running validation accuracy average after each fold. \n",
    "\n",
    "Metric used in optuna optimization is the lower bound of the average validation accuracy from the collective best epoch of all folds measured with the t-distribution at 80% confidence. \n",
    "\n",
    "Each trial is stored using ML Flow and can be viewed by typing mlflow ui in the terminal. \n",
    "\n",
    "Hyperparameter study from optuna uses SQLite and stored in the root project folder using db_path variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d816f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SQLite storage at: sqlite:///optuna_animals10_kfold.db\n",
      "Loaded existing study with 1 previous trials.\n",
      "Could not load existing study: Record does not exist.\n",
      "Best avg validation at epoch 10: 97.79% Â± 0.24%\n",
      "Objective value - t-dist Lower confidence bound (80.0%): 97.64%\n",
      "Trial 1 completed with value: 97.64\n",
      "\n",
      "K-Fold Study statistics:\n",
      "  Number of finished trials: 2\n",
      "  Number of pruned trials: 0\n",
      "  Best trial:\n",
      "    Value: 97.63728594742982 t-dist 80% lower bound\n",
      "    Params:\n",
      "      learning_rate: 0.0001329291894316216\n",
      "      batch_size: 8\n",
      "      weight_decay: 2.9380279387035354e-06\n",
      "      dropout_rate: 0.07799726016810132\n",
      "      augmentation_intensity: medium\n",
      "      patience: 8\n",
      "      max_epochs: 10\n"
     ]
    }
   ],
   "source": [
    "# Run the k-fold cross validation optimization\n",
    "from functions.hyperopt import run_kfold_optuna_optimization\n",
    "db_path = \"optuna_animals10_kfold.db\"\n",
    "k_fold_study = run_kfold_optuna_optimization(\n",
    "    n_trials=1,      # Number of trials\n",
    "    k=3,             # Number of folds\n",
    "    verbose=False,   # Reduce output\n",
    "    storage=db_path, # Store results in SQLite\n",
    "    load_if_exists=True,\n",
    "    first_fold_min_acc=95.0  # Minimum accuracy for the first fold\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
